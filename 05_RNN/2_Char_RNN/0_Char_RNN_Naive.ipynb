{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Recurrent Neural Network\n",
    "- mimicing Shakespeare's writing style\n",
    "- Naive RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "hidden_size = 100\n",
    "batch_size =1\n",
    "num_layers = 1\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "### 1) Prepare characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./data/shakespeare.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions for text processing\n",
    "### 1) Random Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGELO:\n",
      "Now, what's the matter. Provost?\n",
      "\n",
      "Provost:\n",
      "Is it your will Claudio shall die tomorrow?\n",
      "\n",
      "ANGELO:\n",
      "Did not I tell thee yea? hadst thou not order?\n",
      "Why dost thou ask again?\n",
      "\n",
      "Provost:\n",
      "Lest I might be\n"
     ]
    }
   ],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Character to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      " 37\n",
      " 38\n",
      " 13\n",
      " 14\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 6 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor).cuda()\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Chunk into input & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer\n",
    "### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size,hidden_size,num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,hidden = self.rnn(out,hidden)\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        \n",
    "        return out,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, hidden_size)).cuda()\n",
    "        return hidden\n",
    "    \n",
    "model = RNN(n_characters, hidden_size, n_characters, num_layers=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "torch.Size([2, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out,hidden = model(inp,hidden)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden = model(x,hidden)\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        #_,top_i = torch.max(output_dist,dim=0)\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Variable containing:\n",
      " 4.5900\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bx&D+lYOf@zu|C%K/!78/uo14IFamV4U4c8KjncQ9A)`lm;+8t\tAq.I[WK^q8.nm=ZgF3WiTt$b\n",
      "~]1\ttX<.<si\"72;' mB>\tU0,U'Lgp]Z#|#Y\u000b",
      "Rl\f",
      "F[=$h kFTIG_K(t :,EbHhfc4|eh?934*gQdA:Kkx#@G<Lt_]dG3-\u000b",
      "j]f'H7Q;0[)e%X`!}M/z:I8oQ1Aeaze&\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.3506\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bcey ror mey had ored; bau onde thoy houl, whand thoelT olar sod het ene hot modn and sroor be, her;,\n",
      "nee pere dewe\n",
      "E aan yor sf Oard sho to, hamicerd toud thar wour asder froad yel mane mut;\n",
      "Aur ancnd\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.1188\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bloth swense derist'd coth by that me I as theed fove dour angsll afinnt by ot;\n",
      "Bat deme,\n",
      "Ahes fome il to sill phah wat hes\n",
      "And;\n",
      "As it ainct on at ot with me fist as this it cow, at dong stamesing may \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.3692\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "b, sall the the shece woud\n",
      "no storay herthe thie mall be thow thaars fochurd the my say sord,\n",
      "Afpeaf ligh ar ant lichins the por reartes say shakn hall and and ins coothing gind:\n",
      "And of surd in ir mist\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9438\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "be me mar have ardss\n",
      "Or want se marour qe gas's mard solldemay word!\n",
      "\n",
      "CERIO:\n",
      "A he pert prou senter hot it med the.\n",
      "\n",
      "PENMVINIO:\n",
      "And gain, fate, a datishd\n",
      "A gouke ard not fet ap is ske frees, no kin icon\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9605\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bet will cannon theach,\n",
      "And went then his hear ard a hit to then chane, shit fring digliy then, the with facpall sushed faress sirk.\n",
      "\n",
      "BERP:\n",
      "Your dlean,\n",
      "And the kiy, thes as entared your him condy sende\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.0015\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "blass the and in het shan's of and in mand are my souttering the sle worldirsed word, and deme\n",
      "to the same in sole dovend it stale, droke the fid goane\n",
      "Lede to nosh in my se in me le cothers have were \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.1454\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "brour be tame delows juch the say the fore he one the ford buth hath thou he day, he gread will, what hould ands fron, your prople rentine\n",
      "With mecong sue now,\n",
      "Thy not he chall nous:\n",
      "The bercio, I warr\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.0985\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "blould be\n",
      "That done I day, you her prider,\n",
      "And sood.\n",
      "\n",
      "COLIUS:\n",
      "Whon our lad et dalce, our domon's me thouge, trond than do it:\n",
      "And you surt ont new, I hucky of blous pyone him,\n",
      "Her surse\n",
      "I'll come, shey\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9382\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "beto, mine and to be this what sat's sust minedelilice of it sees though leave.\n",
      "\n",
      "MENTIORLIO:\n",
      "I Toundf his the and be to lord, whis hearnet.\n",
      "\n",
      "PIOTINGSLO:\n",
      "I death the bove an stake lived as af be a wirs,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j]\n",
    "        y,hidden = model(x,hidden)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 3\n",
      "[torch.LongTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = torch.Tensor([0.26, 0.24, 0.25, 0.25])\n",
    "\n",
    "for i in range(10):\n",
    "    print(torch.multinomial(weights, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
