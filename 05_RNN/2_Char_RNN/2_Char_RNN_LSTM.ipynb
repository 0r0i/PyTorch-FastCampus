{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Recurrent Neural Network\n",
    "- Mimicing Shakespeare's writing style\n",
    "- Long short-term memory(LSTM)\n",
    "\n",
    "![alt text](./LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "hidden_size = 100\n",
    "batch_size =1\n",
    "num_layers = 1\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "### 1) Prepare characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./data/shakespeare.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions for text processing\n",
    "### 1) Random Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'Rise;' dismiss'd me\n",
      "Thus, with his speechless hand: what he would do,\n",
      "He sent in writing after me; what he would not,\n",
      "Bound with an oath to yield to his conditions:\n",
      "So that all hope is vain.\n",
      "Unless h\n"
     ]
    }
   ],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Character to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      " 37\n",
      " 38\n",
      " 13\n",
      " 14\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 6 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor).cuda()\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Chunk into input & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer\n",
    "### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size,hidden_size,num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden,cell):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        \n",
    "        return out,hidden,cell\n",
    "\n",
    "    def init_hidden(self):\n",
    "          \n",
    "        hidden = Variable(torch.zeros(num_layers,batch_size,hidden_size)).cuda()\n",
    "        cell = Variable(torch.zeros(num_layers,batch_size,hidden_size)).cuda()\n",
    "        \n",
    "        return hidden,cell\n",
    "    \n",
    "model = RNN(n_characters, hidden_size, n_characters, num_layers).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "torch.Size([1, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden,cell = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out,hidden,cell = model(inp,hidden,cell)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden,cell = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden,cell = model(x,hidden,cell)\n",
    "\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Variable containing:\n",
      " 4.5811\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "@J*<^ckZ>vmBxvMOEj_{k*0M\n",
      ")S4oXk6[3QA}9Dw\n",
      "h\f",
      "uaCqyj*^4eEt)47XCj)'C2)p-!'GD\"HU`p!'fT>te|YbP8D}j-J\td\tM'-.z@3B\f",
      "A:Y)k\\jx.*~8\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.5254\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bocsug ort antd thinl to oher louf on ld.\n",
      "oot wuer thanlk at ahos at al, pind y iy lowse houd theres, lohy at chen n beso irt thous fo; slow  sheafoun pou t, tot thonh fow, lod dos the vert, con tosh.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.2337\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bMEbim mome yof tusesth shanst wicad bunth emat the oon,  tare the ees anth loor Ioce mry name?\n",
      "A, an se isu he jostings,\n",
      "That con, stut mond,\n",
      "Lous whe and winde, laulgs the tere be cume of messs esmes\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.3411\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bod; prath theer ing eath it bett at hand tho the have fo fingh thet thell preed dead thath that the auth the:, harve thear is thello mes, wer to Is wrond there hea, ast that 'st, my met my ines?\n",
      "\n",
      "HDEN\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.2515\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bb0er praspes.\n",
      "\n",
      "INAT IO:\n",
      "In ar to at yourde,\n",
      "I at buss that srat to lay dous me hor this kim in his and s all her a id hach omy.\n",
      "Beris bee, an wiagen I ke thern it and hare, the you or rit youste hare \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.1482\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bgnd larest and?\n",
      "\n",
      "CIRAUSENENST:\n",
      "Her bas rust\n",
      "To sowes is twon, hear hand, lor, a in may me for sath wordee? your erto I mat the woer and mor wour I peles wornce your a mild of a stich him sear a live o\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.0099\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bk toioul in nowe he to of be ocen\n",
      "\n",
      "Gold of mo?\n",
      "\n",
      "CALdIO:\n",
      "And mest poucly to no?\n",
      "\n",
      "For I my ars bot to me th then\n",
      "And the in the thour why prevere so thou in me olver mat the bace all tis hous not trithe\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.2458\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "b\n",
      "Mall in lest in that an the dewtur:\n",
      "I your shat as whas my\n",
      "cid the pealed, if wist not of bring that dist the come preven.\n",
      "\n",
      "LUCETLIO:\n",
      "Leath the stall: puhays of wither gath of frean swits\n",
      "Wimy !uttur\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.0703\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bup be lecons o at there sow his this hing and thisouzes the sely sill dades, as lond his ming geaing her criviakings sallled.\n",
      "\n",
      "SINI:\n",
      "Preatiy; to feigh groluter:\n",
      "I candeld faor,\n",
      "Frone to ray coy, and s\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9697\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bood, we nove hither wheom and hom, seriss\n",
      "'TI for pitier, that lice ontent it thaid a see freedsell call that your gide not that hase,\n",
      "Lowes thou make me seat it encow and, deth domeng to not to matte\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.0739\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "b<end stong the men'd not ous came chay are a monteblome cearton your usot's he lousuch so,\n",
      "And s of how we that thy them our fridonouss Macarte manguld for you conce are sur wa, twe fough mum ith the \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9090\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bly shake know counded your pring\n",
      "Shold your for faiff fleane-\"'ll, suthal have will plown shan frobe, so be\n",
      "Thay swithe this sose probe freety.\n",
      "\n",
      "KINGBRABENIO:\n",
      "Goriviis, a preist yould chall thy of anu\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.1995\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bunco trute, tith nood whe the onrow to and do intying ourere weres,\n",
      "Ip I hend how me the spient\n",
      "And heve that grand,\n",
      "Whot thou daster make me manty grren's.\n",
      "\n",
      "DUKENT:\n",
      "Would to thou kingemormones, and o\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9758\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "band whill the be the uppefould, I wat worce\n",
      "And should up bess pare told, of the decauce lipule's sold, sto him the hon,\n",
      "And shill not be digl.\n",
      "\n",
      "ALOUCENCESTIO:\n",
      "The shring have ham for befort say as to\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.2113\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bremy,\n",
      "To lith not and beet a'd brreays mirred with both mighid,\n",
      "I's not parded me the deanded but drom and tile I'tal'd ham and for thene and pray Of floring the leve meabus the betienk thou sire in a\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9899\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "blaus he allin and with worthy his sout whill not the gretio for it what adgretious fake cannot, whil,\n",
      "See houl mane wetle, whoce fatted,\n",
      "Nwards:\n",
      "And 'nhight the to hang pultiep they and to the confe y\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9497\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bled the mairing this it coursess:\n",
      "That the shall sto cir it my do to heaveres wourss to are hoost all am with fore this tayness he look and shalt in the say and heas. I shen thin,\n",
      "For bey our, for hav\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.6628\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "b^chall with of hught, I sick me hadm\n",
      "Bo his it the king the the the sury peadon would swand's from for say,\n",
      "The our doke, broth\n",
      "The say my exath your and, ast I them nidetter sonderath manstreavine: h\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.0446\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bresing the sir shalk mables,\n",
      "And thes we wall tere the am nate, might and my may with so her in thy swast with onour elfour, with the reance ay yet well, the conseam.\n",
      "\n",
      "Frjake! have you proin besonean \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.7846\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n",
      "\n",
      "bury\n",
      "Hear he we, wer shall the had.\n",
      "Bean: do the woult sat I wan spey my.\n",
      "\n",
      "HENCESAl:\n",
      "I bonoughion her froth my strah than you cond of Bather there should to shall to er bown:\n",
      "That be but in the sous.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden,cell = model.init_hidden()\n",
    "\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j]\n",
    "        y,hidden,cell = model(x,hidden,cell)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
